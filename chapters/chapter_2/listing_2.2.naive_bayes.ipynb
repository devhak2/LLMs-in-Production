{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Naive Bayes 분류기 구현하기\n",
        "\n",
        "이 노트북에서는 Naive Bayes 분류기를 처음부터 구현해보겠습니다.\n",
        "햄릿 텍스트를 사용하여 문장에 'be'라는 단어가 포함되는지 여부를 분류하는 이진 분류 모델을 만들어보겠습니다.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. 필요한 라이브러리 및 유틸리티 함수 import\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "라이브러리 및 유틸리티 함수를 성공적으로 import했습니다.\n"
          ]
        }
      ],
      "source": [
        "from utils import process_utt\n",
        "from utils import lookup\n",
        "from nltk.corpus.reader import PlaintextCorpusReader\n",
        "import numpy as np\n",
        "\n",
        "print(\"라이브러리 및 유틸리티 함수를 성공적으로 import했습니다.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. 데이터 로드 및 전처리\n",
        "\n",
        "햄릿 텍스트를 읽어와서 문장들을 준비하고 라벨을 생성합니다.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "총 문장 수: 2660\n",
            "'be'가 포함된 문장 수: 170\n",
            "'be'가 포함되지 않은 문장 수: 2490\n",
            "\n",
            "첫 번째 문장: The Project Gutenberg EBook of Hamlet , by William Shakespeare\n",
            "첫 번째 문장 토큰화: ['the', 'project', 'gutenberg', 'ebook', 'of', 'hamlet', 'by', 'william', 'shakespear']\n",
            "첫 번째 라벨: False\n",
            "\n",
            "159 번째 문장: If thou hast any sound , or use of voice ,[ 18 ] Speak to me : If there be any good thing to be done , That may to thee do ease , and grace to me , Speak to me : If thou art privy to thy country ' s fate , Which , happily , foreknowing may avoid , O , speak !\n",
            "159 번째 문장 토큰화: ['if', 'thou', 'hast', 'ani', 'sound', 'or', 'use', 'of', 'voic', '18', 'speak', 'to', 'me', 'if', 'there', 'be', 'ani', 'good', 'thing', 'to', 'be', 'done', 'that', 'may', 'to', 'thee', 'do', 'eas', 'and', 'grace', 'to', 'me', 'speak', 'to', 'me', 'if', 'thou', 'art', 'privi', 'to', 'thi', 'countri', 's', 'fate', 'which', 'happili', 'foreknow', 'may', 'avoid', 'o', 'speak']\n",
            "159 번째 라벨: True\n"
          ]
        }
      ],
      "source": [
        "# 코퍼스 생성\n",
        "my_corpus = PlaintextCorpusReader(\"../../\", \".*\\.txt\")\n",
        "sents = my_corpus.sents(fileids=\"./data/hamlet.txt\")\n",
        "\n",
        "# 문장들을 문자열로 변환\n",
        "utts = [\" \".join(sent) for sent in sents]\n",
        "\n",
        "# 라벨 생성: 'be'가 포함된 문장은 True(1), 아니면 False(0)\n",
        "ys = [sent.count(\"be\") > 0 for sent in sents]\n",
        "\n",
        "print(f\"총 문장 수: {len(utts)}\")\n",
        "print(f\"'be'가 포함된 문장 수: {sum(ys)}\")\n",
        "print(f\"'be'가 포함되지 않은 문장 수: {len(ys) - sum(ys)}\")\n",
        "print(f\"\\n첫 번째 문장: {utts[0]}\")\n",
        "print(f\"첫 번째 문장 토큰화: {process_utt(utts[0])}\")\n",
        "print(f\"첫 번째 라벨: {ys[0]}\")\n",
        "print(f\"\\n159 번째 문장: {utts[159]}\")\n",
        "print(f\"159 번째 문장 토큰화: {process_utt(utts[159])}\")\n",
        "print(f\"159 번째 라벨: {ys[159]}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. count_utts 함수 구현\n",
        "\n",
        "각 단어와 라벨 쌍의 빈도를 계산하는 함수를 구현합니다.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "count_utts 함수가 정의되었습니다.\n"
          ]
        }
      ],
      "source": [
        "def count_utts(result, utts, ys):\n",
        "    \"\"\"\n",
        "    Input:\n",
        "        result: a dictionary that is used to map each pair to its frequency\n",
        "        utts: a list of utts\n",
        "        ys: a list of the sentiment of each utt (either 0 or 1)\n",
        "    Output:\n",
        "        result: a dictionary mapping each pair to its frequency\n",
        "    \"\"\"\n",
        "\n",
        "    for y, utt in zip(ys, utts):\n",
        "        for word in process_utt(utt):\n",
        "            # define the key, which is the word and label tuple\n",
        "            pair = (word, y)\n",
        "\n",
        "            # if the key exists in the dictionary, increment the count\n",
        "            if pair in result:\n",
        "                result[pair] += 1\n",
        "\n",
        "            # if the key is new, add it to the dict and set the count to 1\n",
        "            else:\n",
        "                result[pair] = 1\n",
        "\n",
        "    return result\n",
        "\n",
        "print(\"count_utts 함수가 정의되었습니다.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. 빈도수 계산 및 확인\n",
        "\n",
        "실제로 단어-라벨 쌍의 빈도를 계산하고 'be' 관련 결과를 확인해봅시다.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "총 (단어, 라벨) 쌍의 개수: 5736\n",
            "\n",
            "'be'가 True 라벨과 함께 나타나는 빈도: 207\n",
            "\n",
            "'be'가 포함된 모든 (단어, 라벨) 쌍:\n",
            "('be', True): 207\n",
            "('be', False): 33\n"
          ]
        }
      ],
      "source": [
        "# 빈도수 계산\n",
        "freqs = count_utts({}, utts, ys)\n",
        "\n",
        "print(f\"총 (단어, 라벨) 쌍의 개수: {len(freqs)}\")\n",
        "\n",
        "# 'be' 단어의 빈도 확인\n",
        "be_true_freq = lookup(freqs, \"be\", True)\n",
        "print(f\"\\n'be'가 True 라벨과 함께 나타나는 빈도: {be_true_freq}\")\n",
        "\n",
        "# 'be'와 관련된 모든 쌍 출력\n",
        "print(\"\\n'be'가 포함된 모든 (단어, 라벨) 쌍:\")\n",
        "for k, v in freqs.items():\n",
        "    if \"be\" in k:\n",
        "        print(f\"{k}: {v}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. train_naive_bayes 함수 구현\n",
        "\n",
        "Naive Bayes 분류기를 훈련하는 함수를 구현합니다. 이 함수는 logprior와 loglikelihood를 계산합니다.\n",
        "# ![베이즈 정리](베이즈정리.png)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train_naive_bayes 함수가 정의되었습니다.\n"
          ]
        }
      ],
      "source": [
        "def train_naive_bayes(freqs, train_x, train_y):\n",
        "    \"\"\"\n",
        "    Input:\n",
        "        freqs: dictionary from (word, label) to how often the word appears\n",
        "        train_x: a list of utts\n",
        "        train_y: a list of labels correponding to the utts (0,1)\n",
        "    Output:\n",
        "        logprior: the log prior.\n",
        "        loglikelihood: the log likelihood of you Naive bayes equation.\n",
        "    \"\"\"\n",
        "    loglikelihood = {}\n",
        "    logprior = 0\n",
        "\n",
        "    # calculate V, the number of unique words in the vocabulary\n",
        "    vocab = set([pair[0] for pair in freqs.keys()])\n",
        "    V = len(vocab)\n",
        "\n",
        "    # calculate N_pos(전체 positive 빈도) and N_neg(전체 negative 빈도)\n",
        "    N_pos = N_neg = 0\n",
        "    for pair in freqs.keys():\n",
        "        # if the label is positive (greater than zero)\n",
        "        if pair[1] > 0:\n",
        "            # Increment the number of positive words (word, label)\n",
        "            N_pos += lookup(freqs, pair[0], True)\n",
        "\n",
        "        # else, the label is negative\n",
        "        else:\n",
        "            # increment the number of negative words (word,label)\n",
        "            N_neg += lookup(freqs, pair[0], False)\n",
        "\n",
        "    # Calculate D, the number of documents(문장)\n",
        "    D = len(train_y)\n",
        "\n",
        "    # Calculate the number of positive documents(positive 문장 수)\n",
        "    D_pos = sum(train_y)\n",
        "\n",
        "    # Calculate the number of negative documents(negative 문장 수)\n",
        "    D_neg = D - D_pos\n",
        "\n",
        "    # Calculate logprior\n",
        "    logprior = np.log(D_pos) - np.log(D_neg)\n",
        "\n",
        "    # For each word in the vocabulary...\n",
        "    for word in vocab:\n",
        "        # get the positive and negative frequency of the word\n",
        "        freq_pos = lookup(freqs, word, 1) # positive 문장에서 해당 단어의 빈도\n",
        "        freq_neg = lookup(freqs, word, 0) # negative 문장에서 해당 단어의 빈도\n",
        "\n",
        "        # calculate the probability that each word is positive, and negative\n",
        "        p_w_pos = (freq_pos + 1) / (N_pos + V) # P(word|positive)\n",
        "        p_w_neg = (freq_neg + 1) / (N_neg + V) # P(word|negative)\n",
        "\n",
        "        # calculate the log likelihood of the word\n",
        "        loglikelihood[word] = np.log(p_w_pos / p_w_neg) # log P(word|positive) - log P(word|negative)\n",
        "\n",
        "    return logprior, loglikelihood\n",
        "\n",
        "print(\"train_naive_bayes 함수가 정의되었습니다.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. 모델 훈련\n",
        "\n",
        "Naive Bayes 모델을 훈련하고 결과를 확인해봅시다.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Log Prior: -2.6842\n",
            "어휘집 크기 (log likelihood 개수): 4574\n",
            "\n",
            "일부 단어들의 log likelihood:\n",
            "'be': 3.1296\n",
            "'to': -0.0386\n",
            "'the': -0.5115\n",
            "'and': -0.2532\n",
            "'of': -0.4823\n",
            "\n",
            "가장 positive한 단어들 (상위 5개):\n",
            "'be': 3.1296\n",
            "'equip': 2.7047\n",
            "'hate': 2.7047\n",
            "'quiddit': 2.7047\n",
            "'_doubt': 2.7047\n",
            "\n",
            "가장 negative한 단어들 (하위 5개):\n",
            "'_enter_': -2.4428\n",
            "'horatio': -2.7247\n",
            "'_and_': -2.7247\n",
            "'_hor': -3.0383\n",
            "'h': -3.4774\n"
          ]
        }
      ],
      "source": [
        "# 모델 훈련\n",
        "logprior, loglikelihood = train_naive_bayes(freqs, utts, ys)\n",
        "\n",
        "print(f\"Log Prior: {logprior:.4f}\")\n",
        "print(f\"어휘집 크기 (log likelihood 개수): {len(loglikelihood)}\")\n",
        "\n",
        "# 몇 가지 단어의 log likelihood 확인\n",
        "print(\"\\n일부 단어들의 log likelihood:\")\n",
        "sample_words = ['be', 'to', 'the', 'and', 'of']\n",
        "for word in sample_words:\n",
        "    if word in loglikelihood:\n",
        "        print(f\"'{word}': {loglikelihood[word]:.4f}\")\n",
        "\n",
        "# 가장 positive한 단어들 (상위 5개)\n",
        "sorted_words = sorted(loglikelihood.items(), key=lambda x: x[1], reverse=True)\n",
        "print(\"\\n가장 positive한 단어들 (상위 5개):\")\n",
        "for word, score in sorted_words[:5]:\n",
        "    print(f\"'{word}': {score:.4f}\")\n",
        "\n",
        "# 가장 negative한 단어들 (하위 5개)\n",
        "print(\"\\n가장 negative한 단어들 (하위 5개):\")\n",
        "for word, score in sorted_words[-5:]:\n",
        "    print(f\"'{word}': {score:.4f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7. naive_bayes_predict 함수 구현\n",
        "\n",
        "주어진 문장에 대해 예측을 수행하는 함수를 구현합니다.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "naive_bayes_predict 함수가 정의되었습니다.\n"
          ]
        }
      ],
      "source": [
        "def naive_bayes_predict(utt, logprior, loglikelihood):\n",
        "    \"\"\"\n",
        "    Input:\n",
        "        utt: a string\n",
        "        logprior: a number\n",
        "        loglikelihood: a dictionary of words mapping to numbers\n",
        "    Output:\n",
        "        p: the sum of all the logliklihoods + logprior\n",
        "    \"\"\"\n",
        "    # process the utt to get a list of words\n",
        "    word_l = process_utt(utt)\n",
        "\n",
        "    # initialize probability to zero\n",
        "    p = 0\n",
        "\n",
        "    # add the logprior\n",
        "    p += logprior\n",
        "\n",
        "    for word in word_l:\n",
        "        # check if the word exists in the loglikelihood dictionary\n",
        "        if word in loglikelihood:\n",
        "            # add the log likelihood of that word to the probability\n",
        "            p += loglikelihood[word]\n",
        "\n",
        "    return p\n",
        "\n",
        "print(\"naive_bayes_predict 함수가 정의되었습니다.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 8. 예측 테스트\n",
        "\n",
        "유명한 햄릿의 대사로 예측을 테스트해봅시다.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "테스트 문장: To be or not to be, that is the question.\n",
            "예측 점수: 2.9321\n",
            "예측 결과: Positive (be 포함될 것으로 예상)\n",
            "실제 결과: be가 포함되어 있음\n",
            "\n",
            "다른 예시들:\n",
            "문장: 'The king is dead.'\n",
            "  점수: -4.5880, 예측: Negative, 실제: be 미포함\n",
            "문장: 'What can be done?'\n",
            "  점수: -0.4041, 예측: Negative, 실제: be 포함\n",
            "문장: 'Hello world, this is a test.'\n",
            "  점수: -3.7019, 예측: Negative, 실제: be 미포함\n",
            "문장: 'I will be there soon.'\n",
            "  점수: -0.0185, 예측: Negative, 실제: be 포함\n"
          ]
        }
      ],
      "source": [
        "# 유명한 햄릿의 대사로 테스트\n",
        "my_utt = \"To be or not to be, that is the question.\"\n",
        "p = naive_bayes_predict(my_utt, logprior, loglikelihood)\n",
        "\n",
        "print(f\"테스트 문장: {my_utt}\")\n",
        "print(f\"예측 점수: {p:.4f}\")\n",
        "print(f\"예측 결과: {'Positive (be 포함될 것으로 예상)' if p > 0 else 'Negative (be 포함되지 않을 것으로 예상)'}\")\n",
        "print(f\"실제 결과: {'be가 포함되어 있음' if 'be' in my_utt.lower() else 'be가 포함되어 있지 않음'}\")\n",
        "\n",
        "# 다른 예시들도 테스트\n",
        "test_sentences = [\n",
        "    \"The king is dead.\",\n",
        "    \"What can be done?\",\n",
        "    \"Hello world, this is a test.\",\n",
        "    \"I will be there soon.\"\n",
        "]\n",
        "\n",
        "print(\"\\n다른 예시들:\")\n",
        "for sentence in test_sentences:\n",
        "    score = naive_bayes_predict(sentence, logprior, loglikelihood)\n",
        "    prediction = \"Positive\" if score > 0 else \"Negative\"\n",
        "    actual = \"be 포함\" if \"be\" in sentence.lower() else \"be 미포함\"\n",
        "    print(f\"문장: '{sentence}'\")\n",
        "    print(f\"  점수: {score:.4f}, 예측: {prediction}, 실제: {actual}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 9. test_naive_bayes 함수 구현\n",
        "\n",
        "모델의 정확도를 계산하는 함수를 구현합니다.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "test_naive_bayes 함수가 정의되었습니다.\n"
          ]
        }
      ],
      "source": [
        "def test_naive_bayes(test_x, test_y, logprior, loglikelihood):\n",
        "    \"\"\"\n",
        "    Input:\n",
        "        test_x: A list of utts\n",
        "        test_y: the corresponding labels for the list of utts\n",
        "        logprior: the logprior\n",
        "        loglikelihood: a dictionary with the loglikelihoods for each word\n",
        "    Output:\n",
        "        accuracy: (# of utts classified correctly)/(total # of utts)\n",
        "    \"\"\"\n",
        "    accuracy = 0  # return this properly\n",
        "\n",
        "    y_hats = []\n",
        "    for utt in test_x:\n",
        "        # if the prediction is > 0\n",
        "        if naive_bayes_predict(utt, logprior, loglikelihood) > 0:\n",
        "            # the predicted class is 1\n",
        "            y_hat_i = 1\n",
        "        else:\n",
        "            # otherwise the predicted class is 0\n",
        "            y_hat_i = 0\n",
        "\n",
        "        # append the predicted class to the list y_hats\n",
        "        y_hats.append(y_hat_i)\n",
        "\n",
        "    # error = avg of the abs vals of the diffs between y_hats and test_y\n",
        "    error = sum(\n",
        "        [abs(y_hat - test) for y_hat, test in zip(y_hats, test_y)]\n",
        "    ) / len(y_hats)\n",
        "\n",
        "    # Accuracy is 1 minus the error\n",
        "    accuracy = 1 - error\n",
        "\n",
        "    return accuracy\n",
        "\n",
        "print(\"test_naive_bayes 함수가 정의되었습니다.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 10. 모델 성능 평가\n",
        "\n",
        "훈련 데이터에서 모델의 정확도를 계산해봅시다.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Naive Bayes 정확도: 0.9801 (98.01%)\n",
            "\n",
            "상세 성능 지표:\n",
            "총 예측 수: 2660\n",
            "정확한 예측 수: 2607\n",
            "True Positives: 124\n",
            "True Negatives: 2483\n",
            "False Positives: 7\n",
            "False Negatives: 46\n",
            "\n",
            "Precision: 0.9466\n",
            "Recall: 0.7294\n",
            "F1 Score: 0.8239\n"
          ]
        }
      ],
      "source": [
        "# 모델 정확도 계산\n",
        "accuracy = test_naive_bayes(utts, ys, logprior, loglikelihood)\n",
        "\n",
        "print(f\"Naive Bayes 정확도: {accuracy:.4f} ({accuracy*100:.2f}%)\")\n",
        "\n",
        "# 추가적인 분석을 위한 예측 결과 확인\n",
        "correct_predictions = 0\n",
        "total_predictions = 0\n",
        "true_positives = 0\n",
        "false_positives = 0\n",
        "true_negatives = 0\n",
        "false_negatives = 0\n",
        "\n",
        "for i, utt in enumerate(utts):\n",
        "    prediction_score = naive_bayes_predict(utt, logprior, loglikelihood)\n",
        "    predicted_label = 1 if prediction_score > 0 else 0\n",
        "    actual_label = ys[i]\n",
        "    \n",
        "    total_predictions += 1\n",
        "    \n",
        "    if predicted_label == actual_label:\n",
        "        correct_predictions += 1\n",
        "        if actual_label == 1:\n",
        "            true_positives += 1\n",
        "        else:\n",
        "            true_negatives += 1\n",
        "    else:\n",
        "        if predicted_label == 1 and actual_label == 0:\n",
        "            false_positives += 1\n",
        "        elif predicted_label == 0 and actual_label == 1:\n",
        "            false_negatives += 1\n",
        "\n",
        "print(f\"\\n상세 성능 지표:\")\n",
        "print(f\"총 예측 수: {total_predictions}\")\n",
        "print(f\"정확한 예측 수: {correct_predictions}\")\n",
        "print(f\"True Positives: {true_positives}\")\n",
        "print(f\"True Negatives: {true_negatives}\")\n",
        "print(f\"False Positives: {false_positives}\")\n",
        "print(f\"False Negatives: {false_negatives}\")\n",
        "\n",
        "# Precision과 Recall 계산\n",
        "precision = true_positives / (true_positives + false_positives) if (true_positives + false_positives) > 0 else 0\n",
        "recall = true_positives / (true_positives + false_negatives) if (true_positives + false_negatives) > 0 else 0\n",
        "f1_score = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
        "\n",
        "print(f\"\\nPrecision: {precision:.4f}\")\n",
        "print(f\"Recall: {recall:.4f}\")\n",
        "print(f\"F1 Score: {f1_score:.4f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 11. 일부 예측 결과 상세 분석\n",
        "\n",
        "몇 가지 예측 결과를 자세히 살펴보겠습니다.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "첫 10개 문장의 예측 결과:\n",
            "--------------------------------------------------------------------------------\n",
            "문장 1: The Project Gutenberg EBook of Hamlet , by William Shakespea...\n",
            "  실제: False, 예측: 0, 점수: -6.5136, ✓\n",
            "\n",
            "문장 2: This eBook is for the use of anyone anywhere at no cost and ...\n",
            "  실제: False, 예측: 0, 점수: -6.7460, ✓\n",
            "\n",
            "문장 3: You may copy it , give it away or re - use it under the term...\n",
            "  실제: False, 예측: 0, 점수: -16.0860, ✓\n",
            "\n",
            "문장 4: Title : Hamlet\n",
            "  실제: False, 예측: 0, 점수: -3.5905, ✓\n",
            "\n",
            "문장 5: Author : William Shakespeare\n",
            "  실제: False, 예측: 0, 점수: -3.8117, ✓\n",
            "\n",
            "문장 6: Editor : Charles Kean\n",
            "  실제: False, 예측: 0, 점수: -3.4476, ✓\n",
            "\n",
            "문장 7: Release Date : January 10 , 2009 [ EBook # 27761 ]\n",
            "  실제: False, 예측: 1, 점수: 1.5141, ✗\n",
            "\n",
            "문장 8: Language : English\n",
            "  실제: False, 예측: 0, 점수: -2.3500, ✓\n",
            "\n",
            "문장 9: Character set encoding : UTF - 8\n",
            "  실제: False, 예측: 0, 점수: -2.0171, ✓\n",
            "\n",
            "문장 10: *** START OF THIS PROJECT GUTENBERG EBOOK HAMLET ***\n",
            "  실제: False, 예측: 0, 점수: -6.5921, ✓\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# 몇 가지 예측 결과를 상세히 분석\n",
        "print(\"첫 10개 문장의 예측 결과:\")\n",
        "print(\"-\" * 80)\n",
        "for i in range(10):\n",
        "    utt = utts[i]\n",
        "    actual = ys[i]\n",
        "    score = naive_bayes_predict(utt, logprior, loglikelihood)\n",
        "    predicted = 1 if score > 0 else 0\n",
        "    \n",
        "    print(f\"문장 {i+1}: {utt[:60]}{'...' if len(utt) > 60 else ''}\")\n",
        "    print(f\"  실제: {actual}, 예측: {predicted}, 점수: {score:.4f}, {'✓' if predicted == actual else '✗'}\")\n",
        "    print()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 12. 모델 파라미터 요약\n",
        "\n",
        "최종적으로 학습된 모델의 주요 파라미터들을 요약해보겠습니다.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "==================================================\n",
            "Naive Bayes 모델 요약\n",
            "==================================================\n",
            "Log Prior: -2.6842\n",
            "어휘집 크기: 4574\n",
            "총 문장 수: 2660\n",
            "Positive 문장 수: 170\n",
            "Negative 문장 수: 2490\n",
            "모델 정확도: 0.9801 (98.01%)\n",
            "Precision: 0.9466\n",
            "Recall: 0.7294\n",
            "F1 Score: 0.8239\n",
            "==================================================\n",
            "\n",
            "모델이 'be 포함'으로 분류하는 데 가장 중요한 단어들:\n",
            "  be: 3.1296\n",
            "  equip: 2.7047\n",
            "  hate: 2.7047\n",
            "  quiddit: 2.7047\n",
            "  _doubt: 2.7047\n",
            "  juic: 2.7047\n",
            "  quillet: 2.7047\n",
            "  plautu: 2.7047\n",
            "  liest: 2.7047\n",
            "  seneca: 2.4170\n",
            "\n",
            "모델이 'be 미포함'으로 분류하는 데 가장 중요한 단어들:\n",
            "  guildenstern: -1.9774\n",
            "  _mar: -2.0138\n",
            "  _exit_: -2.2651\n",
            "  lord: -2.3642\n",
            "  l: -2.3870\n",
            "  _enter_: -2.4428\n",
            "  horatio: -2.7247\n",
            "  _and_: -2.7247\n",
            "  _hor: -3.0383\n",
            "  h: -3.4774\n"
          ]
        }
      ],
      "source": [
        "print(\"=\" * 50)\n",
        "print(\"Naive Bayes 모델 요약\")\n",
        "print(\"=\" * 50)\n",
        "print(f\"Log Prior: {logprior:.4f}\")\n",
        "print(f\"어휘집 크기: {len(loglikelihood)}\")\n",
        "print(f\"총 문장 수: {len(utts)}\")\n",
        "print(f\"Positive 문장 수: {sum(ys)}\")\n",
        "print(f\"Negative 문장 수: {len(ys) - sum(ys)}\")\n",
        "print(f\"모델 정확도: {accuracy:.4f} ({accuracy*100:.2f}%)\")\n",
        "print(f\"Precision: {precision:.4f}\")\n",
        "print(f\"Recall: {recall:.4f}\")\n",
        "print(f\"F1 Score: {f1_score:.4f}\")\n",
        "print(\"=\" * 50)\n",
        "\n",
        "# 모델이 가장 중요하게 생각하는 특징들\n",
        "print(\"\\n모델이 'be 포함'으로 분류하는 데 가장 중요한 단어들:\")\n",
        "for word, score in sorted_words[:10]:\n",
        "    print(f\"  {word}: {score:.4f}\")\n",
        "\n",
        "print(\"\\n모델이 'be 미포함'으로 분류하는 데 가장 중요한 단어들:\")\n",
        "for word, score in sorted_words[-10:]:\n",
        "    print(f\"  {word}: {score:.4f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 결론\n",
        "\n",
        "이 노트북에서 우리는:\n",
        "\n",
        "1. **Naive Bayes 분류기를 처음부터 구현**했습니다\n",
        "2. **햄릿 텍스트를 사용한 이진 분류 문제**를 해결했습니다\n",
        "3. **Log Prior와 Log Likelihood 계산** 과정을 이해했습니다\n",
        "4. **모델의 성능을 다양한 지표로 평가**했습니다\n",
        "5. **단어별 중요도를 분석**하여 모델의 동작을 이해했습니다\n",
        "\n",
        "Naive Bayes는 간단하면서도 효과적인 분류 알고리즘으로, 텍스트 분류, 스팸 필터링, 감정 분석 등 다양한 NLP 작업에 널리 사용됩니다. \"Naive\"라고 불리는 이유는 각 특징(단어)들이 서로 독립적이라는 강한 가정을 하기 때문이지만, 실제로는 이 가정이 성립하지 않아도 놀랍도록 좋은 성능을 보여주는 경우가 많습니다.\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.18"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
