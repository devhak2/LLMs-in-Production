{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# ë§ˆë¥´ì½”í”„ ì²´ì¸ì„ ì´ìš©í•œ í…ìŠ¤íŠ¸ ìƒì„±\n",
        "\n",
        "ì´ ë…¸íŠ¸ë¶ì—ì„œëŠ” ë§ˆë¥´ì½”í”„ ì²´ì¸(Markov Chain)ì„ êµ¬í˜„í•˜ì—¬ í…ìŠ¤íŠ¸ë¥¼ ìƒì„±í•˜ëŠ” ë°©ë²•ì„ ë°°ì›Œë³´ê² ìŠµë‹ˆë‹¤.\n",
        "ë§ˆë¥´ì½”í”„ ì²´ì¸ì€ í˜„ì¬ ìƒíƒœê°€ ì˜¤ì§ ì§ì „ ìƒíƒœì—ë§Œ ì˜ì¡´í•œë‹¤ëŠ” ê°€ì • í•˜ì— ì‘ë™í•˜ëŠ” í™•ë¥ ì  ëª¨ë¸ì…ë‹ˆë‹¤.\n",
        "í…ìŠ¤íŠ¸ ìƒì„±ì—ì„œëŠ” ë‹¤ìŒ ë‹¨ì–´ê°€ í˜„ì¬ ë‹¨ì–´ì—ë§Œ ì˜ì¡´í•œë‹¤ê³  ê°€ì •í•©ë‹ˆë‹¤.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. í•„ìš”í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ import\n",
        "\n",
        "ë§ˆë¥´ì½”í”„ ì²´ì¸ êµ¬í˜„ì— í•„ìš”í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ë“¤ì„ importí•©ë‹ˆë‹¤.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "í•„ìš”í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ë¥¼ ì„±ê³µì ìœ¼ë¡œ importí–ˆìŠµë‹ˆë‹¤.\n"
          ]
        }
      ],
      "source": [
        "import re\n",
        "import random\n",
        "from nltk.tokenize import word_tokenize\n",
        "from collections import defaultdict, deque\n",
        "\n",
        "print(\"í•„ìš”í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ë¥¼ ì„±ê³µì ìœ¼ë¡œ importí–ˆìŠµë‹ˆë‹¤.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. MarkovChain í´ë˜ìŠ¤ì˜ ê¸°ë³¸ êµ¬ì¡°\n",
        "\n",
        "ë§ˆë¥´ì½”í”„ ì²´ì¸ í´ë˜ìŠ¤ë¥¼ ì •ì˜í•˜ê³  ì´ˆê¸°í™” ê³¼ì •ì„ ì‚´í´ë³´ê² ìŠµë‹ˆë‹¤.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ëœë¤ ì‹œë“œë¥¼ ìë™ìœ¼ë¡œ ì„¤ì •í–ˆìŠµë‹ˆë‹¤.\n",
            "ì´ˆê¸° lookup_dict í¬ê¸°: 0\n"
          ]
        }
      ],
      "source": [
        "class MarkovChain:\n",
        "    def __init__(self):\n",
        "        \"\"\"\n",
        "        ë§ˆë¥´ì½”í”„ ì²´ì¸ ì´ˆê¸°í™”\n",
        "        - lookup_dict: ë‹¨ì–´ -> ë‹¤ìŒ ê°€ëŠ¥í•œ ë‹¨ì–´ë“¤ ëª©ë¡ì˜ ë§¤í•‘\n",
        "        - _seeded: ëœë¤ ì‹œë“œ ì„¤ì • ì—¬ë¶€\n",
        "        \"\"\"\n",
        "        self.lookup_dict = defaultdict(list)\n",
        "        self._seeded = False\n",
        "        self.__seed_me()\n",
        "\n",
        "    def __seed_me(self, rand_seed=None):\n",
        "        \"\"\"\n",
        "        ëœë¤ ì‹œë“œ ì„¤ì • ë©”ì„œë“œ\n",
        "        - rand_seed: íŠ¹ì • ì‹œë“œê°’ (Noneì´ë©´ í˜„ì¬ ì‹œê°„ ê¸°ë°˜ìœ¼ë¡œ ìë™ ì„¤ì •)\n",
        "        \"\"\"\n",
        "        if self._seeded is not True:\n",
        "            try:\n",
        "                if rand_seed is not None:\n",
        "                    random.seed(rand_seed)\n",
        "                    print(f\"ëœë¤ ì‹œë“œë¥¼ {rand_seed}ë¡œ ì„¤ì •í–ˆìŠµë‹ˆë‹¤.\")\n",
        "                else:\n",
        "                    random.seed()\n",
        "                    print(\"ëœë¤ ì‹œë“œë¥¼ ìë™ìœ¼ë¡œ ì„¤ì •í–ˆìŠµë‹ˆë‹¤.\")\n",
        "                self._seeded = True\n",
        "            except NotImplementedError:\n",
        "                print(\"ëœë¤ ì‹œë“œ ì„¤ì •ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.\")\n",
        "                self._seeded = False\n",
        "    \n",
        "    def add_document(self, str):\n",
        "        \"\"\"\n",
        "        ë¬¸ì„œë¥¼ ë§ˆë¥´ì½”í”„ ì²´ì¸ì— ì¶”ê°€\n",
        "        1. í…ìŠ¤íŠ¸ ì „ì²˜ë¦¬\n",
        "        2. ë‹¨ì–´ ìŒ ìƒì„±\n",
        "        3. lookup_dictì— ë‹¨ì–´ ìŒë“¤ ì €ì¥\n",
        "        \"\"\"\n",
        "        # 1ë‹¨ê³„: ì „ì²˜ë¦¬\n",
        "        preprocessed_list = self._preprocess(str)\n",
        "        \n",
        "        # 2ë‹¨ê³„: ë‹¨ì–´ ìŒ ìƒì„±\n",
        "        pairs = self._MarkovChain__generate_tuple_keys(preprocessed_list)\n",
        "        \n",
        "        # 3ë‹¨ê³„: lookup_dictì— ì €ì¥\n",
        "        for pair in pairs:\n",
        "            self.lookup_dict[pair[0]].append(pair[1])\n",
        "                \n",
        "    def _preprocess(self, str):\n",
        "        \"\"\"\n",
        "        í…ìŠ¤íŠ¸ ì „ì²˜ë¦¬ ë©”ì„œë“œ\n",
        "        1. ì •ê·œí‘œí˜„ì‹ìœ¼ë¡œ íŠ¹ìˆ˜ë¬¸ìë¥¼ ê³µë°±ìœ¼ë¡œ ëŒ€ì²´\n",
        "        2. ì†Œë¬¸ìë¡œ ë³€í™˜\n",
        "        3. NLTK word_tokenizeë¡œ í† í°í™”\n",
        "        \"\"\"\n",
        "        # 1ë‹¨ê³„: íŠ¹ìˆ˜ë¬¸ì ì œê±° (ì•ŒíŒŒë²³, ìˆ«ìê°€ ì•„ë‹Œ ë¬¸ìë¥¼ ê³µë°±ìœ¼ë¡œ ëŒ€ì²´)\n",
        "        cleaned = re.sub(r\"\\\\W+\", \" \", str).lower()\n",
        "        \n",
        "        # 2ë‹¨ê³„: í† í°í™”\n",
        "        tokenized = word_tokenize(cleaned)\n",
        "        \n",
        "        return tokenized\n",
        "\n",
        "    def __generate_tuple_keys(self, data):\n",
        "        \"\"\"\n",
        "        ì—°ì†ëœ ë‹¨ì–´ ìŒì„ ìƒì„±í•˜ëŠ” ì œë„ˆë ˆì´í„°\n",
        "        [ë‹¨ì–´1, ë‹¨ì–´2, ë‹¨ì–´3, ë‹¨ì–´4] -> [[ë‹¨ì–´1, ë‹¨ì–´2], [ë‹¨ì–´2, ë‹¨ì–´3], [ë‹¨ì–´3, ë‹¨ì–´4]]\n",
        "        \"\"\"\n",
        "        if len(data) < 1:\n",
        "            return\n",
        "        \n",
        "        for i in range(len(data) - 1):\n",
        "            yield [data[i], data[i + 1]]\n",
        "\n",
        "    def generate_text(self, max_length=50):\n",
        "        \"\"\"\n",
        "        ë§ˆë¥´ì½”í”„ ì²´ì¸ì„ ì‚¬ìš©í•˜ì—¬ í…ìŠ¤íŠ¸ ìƒì„±\n",
        "        1. ì‹œì‘ ë‹¨ì–´ ì„ íƒ (ì²« ë²ˆì§¸ í‚¤)\n",
        "        2. í˜„ì¬ ë‹¨ì–´ì—ì„œ ê°€ëŠ¥í•œ ë‹¤ìŒ ë‹¨ì–´ë“¤ ì¤‘ ëœë¤ ì„ íƒ\n",
        "        3. max_lengthì— ë„ë‹¬í•˜ê±°ë‚˜ ë” ì´ìƒ ì—°ê²°í•  ë‹¨ì–´ê°€ ì—†ì„ ë•Œê¹Œì§€ ë°˜ë³µ\n",
        "        \"\"\"\n",
        "        context = deque()  # í˜„ì¬ ì»¨í…ìŠ¤íŠ¸ë¥¼ ì €ì¥í•˜ëŠ” í\n",
        "        output = []        # ìƒì„±ëœ ë‹¨ì–´ë“¤ì„ ì €ì¥í•˜ëŠ” ë¦¬ìŠ¤íŠ¸\n",
        "        \n",
        "        if len(self.lookup_dict) > 0:\n",
        "            # ì‹œë“œ ì¬ì„¤ì • (ì¬í˜„ ê°€ëŠ¥í•œ ê²°ê³¼ë¥¼ ìœ„í•´)\n",
        "            self._MarkovChain__seed_me(rand_seed=len(self.lookup_dict))\n",
        "            \n",
        "            # ì‹œì‘ ë‹¨ì–´ ì„ íƒ (lookup_dictì˜ ì²« ë²ˆì§¸ í‚¤)\n",
        "            chain_head = [list(self.lookup_dict)[0]]\n",
        "            context.extend(chain_head)\n",
        "            \n",
        "            # max_length-1 ë§Œí¼ ë‹¨ì–´ ìƒì„± (ë§ˆì§€ë§‰ì— contextë¥¼ ì¶”ê°€í•˜ë¯€ë¡œ)\n",
        "            while len(output) < (max_length - 1):\n",
        "                # í˜„ì¬ ë‹¨ì–´ì—ì„œ ê°€ëŠ¥í•œ ë‹¤ìŒ ë‹¨ì–´ë“¤ ê°€ì ¸ì˜¤ê¸°\n",
        "                next_choices = self.lookup_dict[context[-1]]\n",
        "                \n",
        "                if len(next_choices) > 0:\n",
        "                    # ê°€ëŠ¥í•œ ì„ íƒì§€ ì¤‘ì—ì„œ ëœë¤í•˜ê²Œ í•˜ë‚˜ ì„ íƒ\n",
        "                    next_word = random.choice(next_choices)\n",
        "                    context.append(next_word)\n",
        "                    output.append(context.popleft())  # íì˜ ì•ìª½ ì›ì†Œë¥¼ ì¶œë ¥ì— ì¶”ê°€\n",
        "                else:\n",
        "                    # ë” ì´ìƒ ì—°ê²°í•  ë‹¨ì–´ê°€ ì—†ìœ¼ë©´ ì¢…ë£Œ\n",
        "                    break\n",
        "                    \n",
        "            # ë‚¨ì€ ì»¨í…ìŠ¤íŠ¸ë¥¼ ì¶œë ¥ì— ì¶”ê°€\n",
        "            output.extend(list(context))\n",
        "            \n",
        "        return \" \".join(output)\n",
        "\n",
        "# í´ë˜ìŠ¤ ì¸ìŠ¤í„´ìŠ¤ ìƒì„± í…ŒìŠ¤íŠ¸\n",
        "test_chain = MarkovChain()\n",
        "print(f\"ì´ˆê¸° lookup_dict í¬ê¸°: {len(test_chain.lookup_dict)}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. ëœë¤ ì‹œë“œ ì„¤ì • ë©”ì„œë“œ\n",
        "\n",
        "ì¬í˜„ ê°€ëŠ¥í•œ ê²°ê³¼ë¥¼ ìœ„í•œ ëœë¤ ì‹œë“œ ì„¤ì • ë©”ì„œë“œë¥¼ êµ¬í˜„í•©ë‹ˆë‹¤.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ì‹œë“œ ì„¤ì • í…ŒìŠ¤íŠ¸:\n",
            "ëœë¤ ì‹œë“œë¥¼ ìë™ìœ¼ë¡œ ì„¤ì •í–ˆìŠµë‹ˆë‹¤.\n",
            "MarkovChain ì¸ìŠ¤í„´ìŠ¤ê°€ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤.\n",
            "lookup_dict íƒ€ì…: <class 'collections.defaultdict'>\n",
            "ì‹œë“œ ì„¤ì • ì™„ë£Œ: True\n",
            "ì‹œë“œ ì„¤ì • ìƒíƒœ: True\n",
            "ëœë¤ ì‹œë“œë¥¼ 42ë¡œ ì„¤ì •í–ˆìŠµë‹ˆë‹¤.\n"
          ]
        }
      ],
      "source": [
        "# ì‹œë“œ ì„¤ì • í…ŒìŠ¤íŠ¸\n",
        "print(\"ì‹œë“œ ì„¤ì • í…ŒìŠ¤íŠ¸:\")\n",
        "test_chain = MarkovChain()\n",
        "print(f\"ì‹œë“œ ì„¤ì • ìƒíƒœ: {test_chain._seeded}\")\n",
        "\n",
        "# íŠ¹ì • ì‹œë“œë¡œ ì¬ì„¤ì •\n",
        "test_chain._seeded = False\n",
        "test_chain._MarkovChain__seed_me(42)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. í…ìŠ¤íŠ¸ ì „ì²˜ë¦¬ ë©”ì„œë“œ\n",
        "\n",
        "ì…ë ¥ í…ìŠ¤íŠ¸ë¥¼ ì •ë¦¬í•˜ê³  í† í°í™”í•˜ëŠ” ì „ì²˜ë¦¬ ê³¼ì •ì„ êµ¬í˜„í•©ë‹ˆë‹¤.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ëœë¤ ì‹œë“œë¥¼ ìë™ìœ¼ë¡œ ì„¤ì •í–ˆìŠµë‹ˆë‹¤.\n",
            "MarkovChain ì¸ìŠ¤í„´ìŠ¤ê°€ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤.\n",
            "lookup_dict íƒ€ì…: <class 'collections.defaultdict'>\n",
            "ì‹œë“œ ì„¤ì • ì™„ë£Œ: True\n",
            "ì›ë³¸ í…ìŠ¤íŠ¸: Hello, World! This is a test. How are you doing today?\n",
            "ì „ì²˜ë¦¬ ê²°ê³¼: ['hello', ',', 'world', '!', 'this', 'is', 'a', 'test', '.', 'how', 'are', 'you', 'doing', 'today', '?']\n",
            "í† í° ê°œìˆ˜: 15\n",
            "\n",
            "ë³µì¡í•œ í…ìŠ¤íŠ¸: To be, or not to be--that is the question!\n",
            "ì „ì²˜ë¦¬ ê²°ê³¼: ['to', 'be', ',', 'or', 'not', 'to', 'be', '--', 'that', 'is', 'the', 'question', '!']\n"
          ]
        }
      ],
      "source": [
        "# ì „ì²˜ë¦¬ í…ŒìŠ¤íŠ¸\n",
        "test_chain = MarkovChain()\n",
        "sample_text = \"Hello, World! This is a test. How are you doing today?\"\n",
        "\n",
        "print(f\"ì›ë³¸ í…ìŠ¤íŠ¸: {sample_text}\")\n",
        "processed = test_chain._preprocess(sample_text)\n",
        "print(f\"ì „ì²˜ë¦¬ ê²°ê³¼: {processed}\")\n",
        "print(f\"í† í° ê°œìˆ˜: {len(processed)}\")\n",
        "\n",
        "# ë” ë³µì¡í•œ ì˜ˆì‹œ\n",
        "complex_text = \"To be, or not to be--that is the question!\"\n",
        "processed_complex = test_chain._preprocess(complex_text)\n",
        "print(f\"\\në³µì¡í•œ í…ìŠ¤íŠ¸: {complex_text}\")\n",
        "print(f\"ì „ì²˜ë¦¬ ê²°ê³¼: {processed_complex}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. ë‹¨ì–´ ìŒ ìƒì„± ë©”ì„œë“œ\n",
        "\n",
        "ì—°ì†ëœ ë‹¨ì–´ë“¤ë¡œë¶€í„° (í˜„ì¬ë‹¨ì–´, ë‹¤ìŒë‹¨ì–´) ìŒì„ ìƒì„±í•˜ëŠ” ë©”ì„œë“œë¥¼ êµ¬í˜„í•©ë‹ˆë‹¤.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ëœë¤ ì‹œë“œë¥¼ ìë™ìœ¼ë¡œ ì„¤ì •í–ˆìŠµë‹ˆë‹¤.\n",
            "MarkovChain ì¸ìŠ¤í„´ìŠ¤ê°€ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤.\n",
            "lookup_dict íƒ€ì…: <class 'collections.defaultdict'>\n",
            "ì‹œë“œ ì„¤ì • ì™„ë£Œ: True\n",
            "ì…ë ¥ ë‹¨ì–´ ë¦¬ìŠ¤íŠ¸: ['to', 'be', 'or', 'not', 'to', 'be']\n",
            "ìƒì„±ëœ ë‹¨ì–´ ìŒë“¤:\n",
            "  1: to -> be\n",
            "  2: be -> or\n",
            "  3: or -> not\n",
            "  4: not -> to\n",
            "  5: to -> be\n",
            "\n",
            "ì´ 5ê°œì˜ ë‹¨ì–´ ìŒì´ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤.\n",
            "ë‹¨ì–´ í•˜ë‚˜ì¸ ê²½ìš° ìƒì„±ëœ ìŒ: 0ê°œ\n"
          ]
        }
      ],
      "source": [
        "# ë‹¨ì–´ ìŒ ìƒì„± í…ŒìŠ¤íŠ¸\n",
        "test_chain = MarkovChain()\n",
        "test_words = [\"to\", \"be\", \"or\", \"not\", \"to\", \"be\"]\n",
        "\n",
        "print(f\"ì…ë ¥ ë‹¨ì–´ ë¦¬ìŠ¤íŠ¸: {test_words}\")\n",
        "print(\"ìƒì„±ëœ ë‹¨ì–´ ìŒë“¤:\")\n",
        "\n",
        "pairs = list(test_chain._MarkovChain__generate_tuple_keys(test_words))\n",
        "for i, pair in enumerate(pairs):\n",
        "    print(f\"  {i+1}: {pair[0]} -> {pair[1]}\")\n",
        "\n",
        "print(f\"\\nì´ {len(pairs)}ê°œì˜ ë‹¨ì–´ ìŒì´ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤.\")\n",
        "\n",
        "# ë‹¨ì–´ í•˜ë‚˜ë§Œ ìˆëŠ” ê²½ìš° í…ŒìŠ¤íŠ¸\n",
        "single_pairs = list(test_chain._MarkovChain__generate_tuple_keys([\"hello\"]))\n",
        "print(f\"ë‹¨ì–´ í•˜ë‚˜ì¸ ê²½ìš° ìƒì„±ëœ ìŒ: {len(single_pairs)}ê°œ\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. ë¬¸ì„œ ì¶”ê°€ ë©”ì„œë“œ\n",
        "\n",
        "í…ìŠ¤íŠ¸ ë¬¸ì„œë¥¼ ë§ˆë¥´ì½”í”„ ì²´ì¸ì— í•™ìŠµì‹œí‚¤ëŠ” ë©”ì„œë“œë¥¼ êµ¬í˜„í•©ë‹ˆë‹¤.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ëœë¤ ì‹œë“œë¥¼ ìë™ìœ¼ë¡œ ì„¤ì •í–ˆìŠµë‹ˆë‹¤.\n",
            "MarkovChain ì¸ìŠ¤í„´ìŠ¤ê°€ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤.\n",
            "lookup_dict íƒ€ì…: <class 'collections.defaultdict'>\n",
            "ì‹œë“œ ì„¤ì • ì™„ë£Œ: True\n",
            "ì¶”ê°€í•  ë¬¸ì„œ 1: The cat sat on the mat. The mat was comfortable.\n",
            "ë¬¸ì„œ ì¶”ê°€ í›„ lookup_dict í¬ê¸°: 8\n",
            "\\nlookup_dict ë‚´ìš©:\n",
            "  'the' -> ['cat', 'mat', 'mat']\n",
            "  'cat' -> ['sat']\n",
            "  'sat' -> ['on']\n",
            "  'on' -> ['the']\n",
            "  'mat' -> ['.', 'was']\n",
            "  '.' -> ['the']\n",
            "  'was' -> ['comfortable']\n",
            "  'comfortable' -> ['.']\n",
            "\\nì¶”ê°€í•  ë¬¸ì„œ 2: The cat likes the mat. The cat sat there.\n",
            "ë¬¸ì„œ ì¶”ê°€ í›„ lookup_dict í¬ê¸°: 10\n",
            "\\nì—…ë°ì´íŠ¸ëœ lookup_dict ë‚´ìš©:\n",
            "  'the' -> ['cat', 'mat', 'mat', 'cat', 'mat', 'cat']\n",
            "  'cat' -> ['sat', 'likes', 'sat']\n",
            "  'sat' -> ['on', 'there']\n",
            "  'on' -> ['the']\n",
            "  'mat' -> ['.', 'was', '.']\n",
            "  '.' -> ['the', 'the']\n",
            "  'was' -> ['comfortable']\n",
            "  'comfortable' -> ['.']\n",
            "  'likes' -> ['the']\n",
            "  'there' -> ['.']\n"
          ]
        }
      ],
      "source": [
        "# ë¬¸ì„œ ì¶”ê°€ í…ŒìŠ¤íŠ¸\n",
        "test_chain = MarkovChain()\n",
        "\n",
        "# ê°„ë‹¨í•œ í…ŒìŠ¤íŠ¸ ë¬¸ì„œ\n",
        "test_doc1 = \"The cat sat on the mat. The mat was comfortable.\"\n",
        "print(f\"ì¶”ê°€í•  ë¬¸ì„œ 1: {test_doc1}\")\n",
        "\n",
        "test_chain.add_document(test_doc1)\n",
        "print(f\"ë¬¸ì„œ ì¶”ê°€ í›„ lookup_dict í¬ê¸°: {len(test_chain.lookup_dict)}\")\n",
        "\n",
        "# lookup_dict ë‚´ìš© í™•ì¸\n",
        "print(\"\\nlookup_dict ë‚´ìš©:\")\n",
        "for key, values in test_chain.lookup_dict.items():\n",
        "    print(f\"  '{key}' -> {values}\")\n",
        "\n",
        "# ë‘ ë²ˆì§¸ ë¬¸ì„œ ì¶”ê°€\n",
        "test_doc2 = \"The cat likes the mat. The cat sat there.\"\n",
        "print(f\"\\nì¶”ê°€í•  ë¬¸ì„œ 2: {test_doc2}\")\n",
        "\n",
        "test_chain.add_document(test_doc2)\n",
        "print(f\"ë¬¸ì„œ ì¶”ê°€ í›„ lookup_dict í¬ê¸°: {len(test_chain.lookup_dict)}\")\n",
        "\n",
        "# ì—…ë°ì´íŠ¸ëœ lookup_dict ë‚´ìš© í™•ì¸\n",
        "print(\"\\nì—…ë°ì´íŠ¸ëœ lookup_dict ë‚´ìš©:\")\n",
        "for key, values in test_chain.lookup_dict.items():\n",
        "    print(f\"  '{key}' -> {values}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7. í…ìŠ¤íŠ¸ ìƒì„± ë©”ì„œë“œ\n",
        "\n",
        "í•™ìŠµëœ ë§ˆë¥´ì½”í”„ ì²´ì¸ì„ ì‚¬ìš©í•˜ì—¬ ìƒˆë¡œìš´ í…ìŠ¤íŠ¸ë¥¼ ìƒì„±í•˜ëŠ” ë©”ì„œë“œë¥¼ êµ¬í˜„í•©ë‹ˆë‹¤.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "í…ìŠ¤íŠ¸ ìƒì„± í…ŒìŠ¤íŠ¸:\n",
            "ëœë¤ ì‹œë“œë¥¼ ìë™ìœ¼ë¡œ ì„¤ì •í–ˆìŠµë‹ˆë‹¤.\n",
            "í›ˆë ¨ í›„ lookup_dict í¬ê¸°: 21\n",
            "\n",
            "ê¸¸ì´ 10ë¡œ ìƒì„±ëœ í…ìŠ¤íŠ¸:\n",
            "  the cat sat on the dog ran in the mat\n",
            "  (ì‹¤ì œ ë‹¨ì–´ ìˆ˜: 10)\n",
            "\n",
            "ê¸¸ì´ 20ë¡œ ìƒì„±ëœ í…ìŠ¤íŠ¸:\n",
            "  the park was happy friends . the park . the mat . the park was soft . the mat was\n",
            "  (ì‹¤ì œ ë‹¨ì–´ ìˆ˜: 20)\n",
            "\n",
            "ê¸¸ì´ 30ë¡œ ìƒì„±ëœ í…ìŠ¤íŠ¸:\n",
            "  the cat sat on the dog ran in the mat . the cat and the dog played together . the dog was excited . they were happy . they were\n",
            "  (ì‹¤ì œ ë‹¨ì–´ ìˆ˜: 30)\n"
          ]
        }
      ],
      "source": [
        "# í…ìŠ¤íŠ¸ ìƒì„± í…ŒìŠ¤íŠ¸\n",
        "print(\"í…ìŠ¤íŠ¸ ìƒì„± í…ŒìŠ¤íŠ¸:\")\n",
        "test_chain = MarkovChain()\n",
        "\n",
        "# ê°„ë‹¨í•œ í›ˆë ¨ ë°ì´í„°\n",
        "training_text = \"\"\"\n",
        "The cat sat on the mat. The cat was happy. The mat was soft.\n",
        "The dog ran in the park. The dog was excited. The park was big.\n",
        "The cat and the dog played together. They were happy friends.\n",
        "\"\"\"\n",
        "\n",
        "test_chain.add_document(training_text)\n",
        "print(f\"í›ˆë ¨ í›„ lookup_dict í¬ê¸°: {len(test_chain.lookup_dict)}\")\n",
        "\n",
        "# ë‹¤ì–‘í•œ ê¸¸ì´ë¡œ í…ìŠ¤íŠ¸ ìƒì„±\n",
        "for length in [10, 20, 30]:\n",
        "    generated = test_chain.generate_text(max_length=length)\n",
        "    print(f\"\\nê¸¸ì´ {length}ë¡œ ìƒì„±ëœ í…ìŠ¤íŠ¸:\")\n",
        "    print(f\"  {generated}\")\n",
        "    print(f\"  (ì‹¤ì œ ë‹¨ì–´ ìˆ˜: {len(generated.split())})\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 8. í–„ë¦¿ í…ìŠ¤íŠ¸ë¡œ ì‹¤ì œ í…ŒìŠ¤íŠ¸\n",
        "\n",
        "ì‹¤ì œ í–„ë¦¿ í…ìŠ¤íŠ¸ë¥¼ ì‚¬ìš©í•˜ì—¬ ë§ˆë¥´ì½”í”„ ì²´ì¸ì„ í›ˆë ¨í•˜ê³  í…ìŠ¤íŠ¸ë¥¼ ìƒì„±í•´ë´…ì‹œë‹¤.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "í–„ë¦¿ í…ìŠ¤íŠ¸ë¥¼ ì„±ê³µì ìœ¼ë¡œ ë¡œë“œí–ˆìŠµë‹ˆë‹¤.\n",
            "í…ìŠ¤íŠ¸ ê¸¸ì´: 221,777 ë¬¸ì\n",
            "ì²˜ìŒ 200ì: The Project Gutenberg EBook of Hamlet, by William Shakespeare\n",
            "\n",
            "This eBook is for the use of anyone anywhere at no cost and with\n",
            "almost no restrictions whatsoever.  You may copy it, give it away or\n",
            "re-...\n",
            "ëœë¤ ì‹œë“œë¥¼ ìë™ìœ¼ë¡œ ì„¤ì •í–ˆìŠµë‹ˆë‹¤.\n",
            "\n",
            "í›ˆë ¨ ì™„ë£Œ!\n",
            "í•™ìŠµëœ ë‹¨ì–´ ìˆ˜: 6785\n",
            "\n",
            "ì¼ë¶€ ë‹¨ì–´ë“¤ì˜ ë‹¤ìŒ ë‹¨ì–´ í›„ë³´ë“¤:\n",
            "  'the' -> 1460ê°œ ì„ íƒì§€: ['project', 'use', 'terms', 'project', 'online', 'book', 'bottom', 'footnotes', 'end', 'word']...\n",
            "  'to' -> 822ê°œ ì„ íƒì§€: ['unmix', 'act', 'act', 'the', 'the', 'hamlet_', 'polonius_', 'command', 'future', 'be']...\n",
            "  'and' -> 808ê°œ ì„ íƒì§€: ['with', 'the', 'evans', 'evans', 'admiration', 'as', 'amiable', 'the', 'most', 'feeling']...\n",
            "  'be' -> 214ê°œ ì„ íƒì§€: ['on', 'found', 'easily', 'selected', 'spoke', 'any', 'done', 'green', 'contracted', 'thine']...\n",
            "  'of' -> 913ê°œ ì„ íƒì§€: ['hamlet', 'anyone', 'the', 'this', '_hamlet_', 'each', 'each', 'hamlet', 'denmark', 'denmark_']...\n"
          ]
        }
      ],
      "source": [
        "# í–„ë¦¿ í…ìŠ¤íŠ¸ ë¡œë“œ ë° ë§ˆë¥´ì½”í”„ ì²´ì¸ í›ˆë ¨\n",
        "try:\n",
        "    with open(\"../../data/hamlet.txt\", \"r\", encoding=\"utf-8\") as f:\n",
        "        hamlet_text = f.read()\n",
        "    print(\"í–„ë¦¿ í…ìŠ¤íŠ¸ë¥¼ ì„±ê³µì ìœ¼ë¡œ ë¡œë“œí–ˆìŠµë‹ˆë‹¤.\")\n",
        "    print(f\"í…ìŠ¤íŠ¸ ê¸¸ì´: {len(hamlet_text):,} ë¬¸ì\")\n",
        "    print(f\"ì²˜ìŒ 200ì: {hamlet_text[:200]}...\")\n",
        "    \n",
        "except FileNotFoundError:\n",
        "    print(\"í–„ë¦¿ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ìƒ˜í”Œ í…ìŠ¤íŠ¸ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.\")\n",
        "    hamlet_text = \"\"\"\n",
        "    To be or not to be, that is the question. Whether tis nobler in the mind to suffer\n",
        "    the slings and arrows of outrageous fortune, or to take arms against a sea of troubles\n",
        "    and by opposing end them. To die, to sleep, no more, and by a sleep to say we end\n",
        "    the heartache and the thousand natural shocks that flesh is heir to.\n",
        "    \"\"\"\n",
        "\n",
        "# ë§ˆë¥´ì½”í”„ ì²´ì¸ ìƒì„± ë° í›ˆë ¨\n",
        "HMM = MarkovChain()\n",
        "HMM.add_document(hamlet_text)\n",
        "\n",
        "print(f\"\\ní›ˆë ¨ ì™„ë£Œ!\")\n",
        "print(f\"í•™ìŠµëœ ë‹¨ì–´ ìˆ˜: {len(HMM.lookup_dict)}\")\n",
        "\n",
        "# ì¼ë¶€ ë‹¨ì–´ì˜ ë‹¤ìŒ ë‹¨ì–´ í›„ë³´ë“¤ í™•ì¸\n",
        "sample_words = ['the', 'to', 'and', 'be', 'of']\n",
        "print(\"\\nì¼ë¶€ ë‹¨ì–´ë“¤ì˜ ë‹¤ìŒ ë‹¨ì–´ í›„ë³´ë“¤:\")\n",
        "for word in sample_words:\n",
        "    if word in HMM.lookup_dict:\n",
        "        next_words = HMM.lookup_dict[word]\n",
        "        print(f\"  '{word}' -> {len(next_words)}ê°œ ì„ íƒì§€: {next_words[:10]}{'...' if len(next_words) > 10 else ''}\")\n",
        "    else:\n",
        "        print(f\"  '{word}' -> ë‹¨ì–´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 10. ë‹¤ì–‘í•œ ê¸¸ì´ì˜ í…ìŠ¤íŠ¸ ìƒì„±\n",
        "\n",
        "í›ˆë ¨ëœ ë§ˆë¥´ì½”í”„ ì²´ì¸ìœ¼ë¡œ ë‹¤ì–‘í•œ ê¸¸ì´ì˜ í…ìŠ¤íŠ¸ë¥¼ ìƒì„±í•´ë´…ì‹œë‹¤.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "í–„ë¦¿ ìŠ¤íƒ€ì¼ í…ìŠ¤íŠ¸ ìƒì„± ê²°ê³¼:\n",
            "============================================================\n",
            "\n",
            "1. ëª©í‘œ ê¸¸ì´: 15ë‹¨ì–´ (ì‹¤ì œ: 15ë‹¨ì–´)\n",
            "   the hilts , [ footnote iv.16 : _green_ ; you to her ? _fran._ for\n",
            "\n",
            "2. ëª©í‘œ ê¸¸ì´: 25ë‹¨ì–´ (ì‹¤ì œ: 25ë‹¨ì–´)\n",
            "   the sixteenth century afterwards . polonius , or reason and passion will not beteem_ ] the loss your heart , they say ) _king._ (\n",
            "\n",
            "3. ëª©í‘œ ê¸¸ì´: 35ë‹¨ì–´ (ì‹¤ì œ: 35ë‹¨ì–´)\n",
            "   the important foe . _dan._ we may colour [ footnote iii.91 : [ 44 ] contumacious towards . _pol._ ( r. ) that rots itself more of't ; the danger of in his wit ,\n",
            "\n",
            "4. ëª©í‘œ ê¸¸ì´: 50ë‹¨ì–´ (ì‹¤ì œ: 50ë‹¨ì–´)\n",
            "   the owner of playing upon me from the time , and the terms of my beard , he was once in this folly drowns it._ ] _laer._ ( r. ) custom which the modesty as mad : _this grave rain many others . ] _queen._ ( c. centre of our\n",
            "\n",
            "============================================================\n",
            "25ë‹¨ì–´ ê¸¸ì´ë¡œ 5ë²ˆ ìƒì„± (ë‹¤ì–‘ì„± í™•ì¸):\n",
            "----------------------------------------\n",
            "ëœë¤ ì‹œë“œë¥¼ 6785ë¡œ ì„¤ì •í–ˆìŠµë‹ˆë‹¤.\n",
            "1. the carpenter ? _ ] freeze thy mother 's daughter._ ] [ 48 ] ah , rosencrantz . [ 93 ] _i.e._ , folded .\n",
            "ëœë¤ ì‹œë“œë¥¼ 6785ë¡œ ì„¤ì •í–ˆìŠµë‹ˆë‹¤.\n",
            "2. the carpenter ? _ ] freeze thy mother 's daughter._ ] [ 48 ] ah , rosencrantz . [ 93 ] _i.e._ , folded .\n",
            "ëœë¤ ì‹œë“œë¥¼ 6785ë¡œ ì„¤ì •í–ˆìŠµë‹ˆë‹¤.\n",
            "3. the carpenter ? _ ] freeze thy mother 's daughter._ ] [ 48 ] ah , rosencrantz . [ 93 ] _i.e._ , folded .\n",
            "ëœë¤ ì‹œë“œë¥¼ 6785ë¡œ ì„¤ì •í–ˆìŠµë‹ˆë‹¤.\n",
            "4. the carpenter ? _ ] freeze thy mother 's daughter._ ] [ 48 ] ah , rosencrantz . [ 93 ] _i.e._ , folded .\n",
            "ëœë¤ ì‹œë“œë¥¼ 6785ë¡œ ì„¤ì •í–ˆìŠµë‹ˆë‹¤.\n",
            "5. the carpenter ? _ ] freeze thy mother 's daughter._ ] [ 48 ] ah , rosencrantz . [ 93 ] _i.e._ , folded .\n"
          ]
        }
      ],
      "source": [
        "# ë‹¤ì–‘í•œ ê¸¸ì´ì˜ í…ìŠ¤íŠ¸ ìƒì„±\n",
        "lengths = [15, 25, 35, 50]\n",
        "\n",
        "print(\"í–„ë¦¿ ìŠ¤íƒ€ì¼ í…ìŠ¤íŠ¸ ìƒì„± ê²°ê³¼:\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "for i, length in enumerate(lengths, 1):\n",
        "    generated = HMM.generate_text(max_length=length)\n",
        "    actual_length = len(generated.split())\n",
        "    \n",
        "    print(f\"\\n{i}. ëª©í‘œ ê¸¸ì´: {length}ë‹¨ì–´ (ì‹¤ì œ: {actual_length}ë‹¨ì–´)\")\n",
        "    print(f\"   {generated}\")\n",
        "\n",
        "# ì—¬ëŸ¬ ë²ˆ ìƒì„±í•˜ì—¬ ë‹¤ì–‘ì„± í™•ì¸\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"25ë‹¨ì–´ ê¸¸ì´ë¡œ 5ë²ˆ ìƒì„± (ë‹¤ì–‘ì„± í™•ì¸):\")\n",
        "print(\"-\" * 40)\n",
        "\n",
        "for i in range(5):\n",
        "    # ì‹œë“œë¥¼ ë‹¤ì‹œ ì„¤ì •í•˜ì—¬ ë‹¤ë¥¸ ê²°ê³¼ ìƒì„±\n",
        "    HMM._seeded = False\n",
        "    generated = HMM.generate_text(max_length=25)\n",
        "    print(f\"{i+1}. {generated}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 11. ë§ˆë¥´ì½”í”„ ì²´ì¸ ë¶„ì„\n",
        "\n",
        "í•™ìŠµëœ ë§ˆë¥´ì½”í”„ ì²´ì¸ì˜ íŠ¹ì„±ì„ ë¶„ì„í•´ë³´ê² ìŠµë‹ˆë‹¤.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ë§ˆë¥´ì½”í”„ ì²´ì¸ ë¶„ì„ ê²°ê³¼:\n",
            "==================================================\n",
            "ê³ ìœ  ë‹¨ì–´ ìˆ˜: 6,785\n",
            "ì „ì²´ ì „ì´(transition) ìˆ˜: 47,019\n",
            "í‰ê·  ì „ì´ ìˆ˜ per ë‹¨ì–´: 6.93\n",
            "\n",
            "ê°€ì¥ ë§ì€ ì„ íƒì§€ë¥¼ ê°€ì§„ ë‹¨ì–´ë“¤ (Top 10):\n",
            "   1. ',': 3442ê°œ ì„ íƒì§€\n",
            "   2. '.': 1696ê°œ ì„ íƒì§€\n",
            "   3. ']': 1600ê°œ ì„ íƒì§€\n",
            "   4. 'the': 1460ê°œ ì„ íƒì§€\n",
            "   5. '[': 1131ê°œ ì„ íƒì§€\n",
            "   6. 'of': 913ê°œ ì„ íƒì§€\n",
            "   7. ':': 882ê°œ ì„ íƒì§€\n",
            "   8. 'to': 822ê°œ ì„ íƒì§€\n",
            "   9. 'and': 808ê°œ ì„ íƒì§€\n",
            "  10. 'a': 661ê°œ ì„ íƒì§€\n",
            "\n",
            "ê°€ì¥ ì ì€ ì„ íƒì§€ë¥¼ ê°€ì§„ ë‹¨ì–´ë“¤ (Bottom 10):\n",
            "   1. 'confirmed': 1ê°œ ì„ íƒì§€\n",
            "   2. 'necessarily': 1ê°œ ì„ íƒì§€\n",
            "   3. 'main': 1ê°œ ì„ íƒì§€\n",
            "   4. 'pg': 1ê°œ ì„ íƒì§€\n",
            "   5. 'facility': 1ê°œ ì„ íƒì§€\n",
            "   6. '//www.gutenberg.org': 1ê°œ ì„ íƒì§€\n",
            "   7. 'includes': 1ê°œ ì„ íƒì§€\n",
            "   8. 'produce': 1ê°œ ì„ íƒì§€\n",
            "   9. 'subscribe': 1ê°œ ì„ íƒì§€\n",
            "  10. 'newsletter': 1ê°œ ì„ íƒì§€\n",
            "\n",
            "ì„ íƒì§€ ìˆ˜ í†µê³„:\n",
            "  ìµœëŒ€: 3442\n",
            "  ìµœì†Œ: 1\n",
            "  í‰ê· : 6.93\n",
            "  ì¤‘ê°„ê°’: 1\n",
            "\n",
            "íŠ¹ì • ë‹¨ì–´ë“¤ì˜ ë‹¤ìŒ ë‹¨ì–´ ë¶„ì„:\n",
            "  'to' -> ì´ 822ê°œ ì „ì´:\n",
            "    'the': 89íšŒ (10.8%)\n",
            "    'be': 45íšŒ (5.5%)\n",
            "    'you': 22íšŒ (2.7%)\n",
            "    'a': 19íšŒ (2.3%)\n",
            "    'his': 18íšŒ (2.2%)\n",
            "  'the' -> ì´ 1460ê°œ ì „ì´:\n",
            "    'king': 34íšŒ (2.3%)\n",
            "    'project': 31íšŒ (2.1%)\n",
            "    'same': 16íšŒ (1.1%)\n",
            "    'very': 15íšŒ (1.0%)\n",
            "    'world': 13íšŒ (0.9%)\n",
            "  'be' -> ì´ 214ê°œ ì „ì´:\n",
            "    ',': 13íšŒ (6.1%)\n",
            "    'the': 10íšŒ (4.7%)\n",
            "    'a': 10íšŒ (4.7%)\n",
            "    'so': 5íšŒ (2.3%)\n",
            "    'found': 4íšŒ (1.9%)\n",
            "  'that' -> ì´ 348ê°œ ì „ì´:\n",
            "    'i': 24íšŒ (6.9%)\n",
            "    ',': 19íšŒ (5.5%)\n",
            "    'the': 15íšŒ (4.3%)\n",
            "    'is': 15íšŒ (4.3%)\n",
            "    'you': 15íšŒ (4.3%)\n",
            "  'and' -> ì´ 808ê°œ ì „ì´:\n",
            "    'the': 39íšŒ (4.8%)\n",
            "    ',': 31íšŒ (3.8%)\n",
            "    'you': 13íšŒ (1.6%)\n",
            "    'that': 10íšŒ (1.2%)\n",
            "    'my': 10íšŒ (1.2%)\n"
          ]
        }
      ],
      "source": [
        "# ë§ˆë¥´ì½”í”„ ì²´ì¸ í†µê³„ ë¶„ì„\n",
        "print(\"ë§ˆë¥´ì½”í”„ ì²´ì¸ ë¶„ì„ ê²°ê³¼:\")\n",
        "print(\"=\" * 50)\n",
        "\n",
        "# ì „ì²´ í†µê³„\n",
        "total_words = len(HMM.lookup_dict)\n",
        "total_transitions = sum(len(transitions) for transitions in HMM.lookup_dict.values())\n",
        "\n",
        "print(f\"ê³ ìœ  ë‹¨ì–´ ìˆ˜: {total_words:,}\")\n",
        "print(f\"ì „ì²´ ì „ì´(transition) ìˆ˜: {total_transitions:,}\")\n",
        "print(f\"í‰ê·  ì „ì´ ìˆ˜ per ë‹¨ì–´: {total_transitions/total_words:.2f}\")\n",
        "\n",
        "# ê°€ì¥ ë§ì€ ë‹¤ìŒ ë‹¨ì–´ ì„ íƒì§€ë¥¼ ê°€ì§„ ë‹¨ì–´ë“¤\n",
        "word_choice_counts = [(word, len(choices)) for word, choices in HMM.lookup_dict.items()]\n",
        "word_choice_counts.sort(key=lambda x: x[1], reverse=True)\n",
        "\n",
        "print(\"\\nê°€ì¥ ë§ì€ ì„ íƒì§€ë¥¼ ê°€ì§„ ë‹¨ì–´ë“¤ (Top 10):\")\n",
        "for i, (word, count) in enumerate(word_choice_counts[:10], 1):\n",
        "    print(f\"  {i:2d}. '{word}': {count}ê°œ ì„ íƒì§€\")\n",
        "\n",
        "# ê°€ì¥ ì ì€ ì„ íƒì§€ë¥¼ ê°€ì§„ ë‹¨ì–´ë“¤\n",
        "print(\"\\nê°€ì¥ ì ì€ ì„ íƒì§€ë¥¼ ê°€ì§„ ë‹¨ì–´ë“¤ (Bottom 10):\")\n",
        "for i, (word, count) in enumerate(word_choice_counts[-10:], 1):\n",
        "    print(f\"  {i:2d}. '{word}': {count}ê°œ ì„ íƒì§€\")\n",
        "\n",
        "# ì„ íƒì§€ ìˆ˜ì˜ ë¶„í¬\n",
        "choice_counts = [count for _, count in word_choice_counts]\n",
        "print(f\"\\nì„ íƒì§€ ìˆ˜ í†µê³„:\")\n",
        "print(f\"  ìµœëŒ€: {max(choice_counts)}\")\n",
        "print(f\"  ìµœì†Œ: {min(choice_counts)}\")\n",
        "print(f\"  í‰ê· : {sum(choice_counts)/len(choice_counts):.2f}\")\n",
        "print(f\"  ì¤‘ê°„ê°’: {sorted(choice_counts)[len(choice_counts)//2]}\")\n",
        "\n",
        "# íŠ¹ì • ë‹¨ì–´ë“¤ì˜ ì „ì´ í™•ì¸\n",
        "print(\"\\níŠ¹ì • ë‹¨ì–´ë“¤ì˜ ë‹¤ìŒ ë‹¨ì–´ ë¶„ì„:\")\n",
        "interesting_words = ['to', 'the', 'be', 'that', 'and']\n",
        "for word in interesting_words:\n",
        "    if word in HMM.lookup_dict:\n",
        "        choices = HMM.lookup_dict[word]\n",
        "        # ê° ì„ íƒì§€ì˜ ë¹ˆë„ ê³„ì‚°\n",
        "        from collections import Counter\n",
        "        choice_freq = Counter(choices)\n",
        "        top_choices = choice_freq.most_common(5)\n",
        "        print(f\"  '{word}' -> ì´ {len(choices)}ê°œ ì „ì´:\")\n",
        "        for next_word, freq in top_choices:\n",
        "            percentage = (freq/len(choices))*100\n",
        "            print(f\"    '{next_word}': {freq}íšŒ ({percentage:.1f}%)\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 12. ë§ˆë¥´ì½”í”„ ì²´ì¸ì˜ í•œê³„ì™€ ê°œì„ ì \n",
        "\n",
        "ë§ˆë¥´ì½”í”„ ì²´ì¸ì˜ ì¥ë‹¨ì ì„ ì‚´í´ë³´ê³ , ì‹¤ì œ ìƒì„± ê²°ê³¼ë¥¼ ë¶„ì„í•´ë´…ì‹œë‹¤.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ë§ˆë¥´ì½”í”„ ì²´ì¸ì˜ ì¥ë‹¨ì  ë¶„ì„:\n",
            "==================================================\n",
            "\n",
            "âœ… ì¥ì :\n",
            "  1. êµ¬í˜„ì´ ê°„ë‹¨í•˜ê³  ì§ê´€ì \n",
            "  2. í•™ìŠµ ì†ë„ê°€ ë¹ ë¦„\n",
            "  3. ë©”ëª¨ë¦¬ íš¨ìœ¨ì \n",
            "  4. ì›ë³¸ í…ìŠ¤íŠ¸ì˜ êµ­ë¶€ì  íŒ¨í„´ì„ ì˜ í•™ìŠµ\n",
            "\n",
            "âŒ ë‹¨ì :\n",
            "  1. ì¥ê±°ë¦¬ ì˜ì¡´ì„±(long-range dependency)ë¥¼ í¬ì°©í•  ìˆ˜ ì—†ìŒ\n",
            "  2. ë¬¸ë²•ì  ì¼ê´€ì„±ì´ ë–¨ì–´ì§ˆ ìˆ˜ ìˆìŒ\n",
            "  3. ì˜ë¯¸ì  ì—°ê´€ì„±ì´ ë¶€ì¡±í•  ìˆ˜ ìˆìŒ\n",
            "  4. 1ì°¨ ë§ˆë¥´ì½”í”„ ì²´ì¸ì€ ë„ˆë¬´ ë‹¨ìˆœí•¨\n",
            "\n",
            "ğŸ”§ ê°œì„  ë°©ì•ˆ:\n",
            "  1. ê³ ì°¨ ë§ˆë¥´ì½”í”„ ì²´ì¸ (2-gram, 3-gram ë“±)\n",
            "  2. í‰í™œí™”(Smoothing) ê¸°ë²• ì ìš©\n",
            "  3. ë°±ì˜¤í”„(Backoff) ì „ëµ\n",
            "  4. ê°€ì¤‘ì¹˜ ê¸°ë°˜ ì„ íƒ\n",
            "\n",
            "ğŸ“Š ìƒì„±ëœ í…ìŠ¤íŠ¸ í’ˆì§ˆ ë¶„ì„:\n",
            "ëœë¤ ì‹œë“œë¥¼ 6785ë¡œ ì„¤ì •í–ˆìŠµë‹ˆë‹¤.\n",
            "  1. the carpenter ? _ ] freeze thy mother 's daughter._ ] [ 48 ] ah , rosencrantz . [ 93\n",
            "ëœë¤ ì‹œë“œë¥¼ 6785ë¡œ ì„¤ì •í–ˆìŠµë‹ˆë‹¤.\n",
            "  2. the carpenter ? _ ] freeze thy mother 's daughter._ ] [ 48 ] ah , rosencrantz . [ 93\n",
            "ëœë¤ ì‹œë“œë¥¼ 6785ë¡œ ì„¤ì •í–ˆìŠµë‹ˆë‹¤.\n",
            "  3. the carpenter ? _ ] freeze thy mother 's daughter._ ] [ 48 ] ah , rosencrantz . [ 93\n",
            "ëœë¤ ì‹œë“œë¥¼ 6785ë¡œ ì„¤ì •í–ˆìŠµë‹ˆë‹¤.\n",
            "  4. the carpenter ? _ ] freeze thy mother 's daughter._ ] [ 48 ] ah , rosencrantz . [ 93\n",
            "ëœë¤ ì‹œë“œë¥¼ 6785ë¡œ ì„¤ì •í–ˆìŠµë‹ˆë‹¤.\n",
            "  5. the carpenter ? _ ] freeze thy mother 's daughter._ ] [ 48 ] ah , rosencrantz . [ 93\n",
            "\n",
            "ë¶„ì„ ê²°ê³¼:\n",
            "  - ë¬¸ë²•ì  ì™„ì„±ë„: ì¤‘ê°„ ìˆ˜ì¤€\n",
            "  - ì˜ë¯¸ì  ì¼ê´€ì„±: ë‚®ìŒ\n",
            "  - ì›ë³¸ í…ìŠ¤íŠ¸ì™€ì˜ ìœ ì‚¬ì„±: ë†’ìŒ\n",
            "  - ì°½ì˜ì„±: ì œí•œì \n",
            "\n",
            "ì›ë³¸ í–„ë¦¿ì—ì„œ ì‹¤ì œ ë¬¸ì¥ ì˜ˆì‹œ:\n",
            "  1. The Project Gutenberg EBook of Hamlet, by William Shakespeare This eBook is for ...\n",
            "  2. You may copy it, give it away or re-use it under the terms of the Project Gutenb...\n",
            "  3. gutenberg...\n"
          ]
        }
      ],
      "source": [
        "# ë§ˆë¥´ì½”í”„ ì²´ì¸ì˜ íŠ¹ì„± ë¶„ì„\n",
        "\n",
        "print(\"ë§ˆë¥´ì½”í”„ ì²´ì¸ì˜ ì¥ë‹¨ì  ë¶„ì„:\")\n",
        "print(\"=\" * 50)\n",
        "\n",
        "print(\"\\nâœ… ì¥ì :\")\n",
        "print(\"  1. êµ¬í˜„ì´ ê°„ë‹¨í•˜ê³  ì§ê´€ì \")\n",
        "print(\"  2. í•™ìŠµ ì†ë„ê°€ ë¹ ë¦„\")\n",
        "print(\"  3. ë©”ëª¨ë¦¬ íš¨ìœ¨ì \")\n",
        "print(\"  4. ì›ë³¸ í…ìŠ¤íŠ¸ì˜ êµ­ë¶€ì  íŒ¨í„´ì„ ì˜ í•™ìŠµ\")\n",
        "\n",
        "print(\"\\nâŒ ë‹¨ì :\")\n",
        "print(\"  1. ì¥ê±°ë¦¬ ì˜ì¡´ì„±(long-range dependency)ë¥¼ í¬ì°©í•  ìˆ˜ ì—†ìŒ\")\n",
        "print(\"  2. ë¬¸ë²•ì  ì¼ê´€ì„±ì´ ë–¨ì–´ì§ˆ ìˆ˜ ìˆìŒ\")\n",
        "print(\"  3. ì˜ë¯¸ì  ì—°ê´€ì„±ì´ ë¶€ì¡±í•  ìˆ˜ ìˆìŒ\")\n",
        "print(\"  4. 1ì°¨ ë§ˆë¥´ì½”í”„ ì²´ì¸ì€ ë„ˆë¬´ ë‹¨ìˆœí•¨\")\n",
        "\n",
        "# ê°œì„  ë°©ì•ˆ ì‹œë®¬ë ˆì´ì…˜: 2ì°¨ ë§ˆë¥´ì½”í”„ ì²´ì¸ ì•„ì´ë””ì–´\n",
        "print(\"\\nğŸ”§ ê°œì„  ë°©ì•ˆ:\")\n",
        "print(\"  1. ê³ ì°¨ ë§ˆë¥´ì½”í”„ ì²´ì¸ (2-gram, 3-gram ë“±)\")\n",
        "print(\"  2. í‰í™œí™”(Smoothing) ê¸°ë²• ì ìš©\")\n",
        "print(\"  3. ë°±ì˜¤í”„(Backoff) ì „ëµ\")\n",
        "print(\"  4. ê°€ì¤‘ì¹˜ ê¸°ë°˜ ì„ íƒ\")\n",
        "\n",
        "# ì‹¤ì œ ìƒì„± í…ìŠ¤íŠ¸ì˜ ë¬¸ì œì  ë¶„ì„\n",
        "print(\"\\nğŸ“Š ìƒì„±ëœ í…ìŠ¤íŠ¸ í’ˆì§ˆ ë¶„ì„:\")\n",
        "sample_generations = []\n",
        "for i in range(5):\n",
        "    HMM._seeded = False\n",
        "    text = HMM.generate_text(max_length=20)\n",
        "    sample_generations.append(text)\n",
        "    print(f\"  {i+1}. {text}\")\n",
        "\n",
        "print(\"\\në¶„ì„ ê²°ê³¼:\")\n",
        "print(\"  - ë¬¸ë²•ì  ì™„ì„±ë„: ì¤‘ê°„ ìˆ˜ì¤€\")\n",
        "print(\"  - ì˜ë¯¸ì  ì¼ê´€ì„±: ë‚®ìŒ\")\n",
        "print(\"  - ì›ë³¸ í…ìŠ¤íŠ¸ì™€ì˜ ìœ ì‚¬ì„±: ë†’ìŒ\")\n",
        "print(\"  - ì°½ì˜ì„±: ì œí•œì \")\n",
        "\n",
        "# ì›ë³¸ í…ìŠ¤íŠ¸ì™€ì˜ ë¹„êµ\n",
        "print(\"\\nì›ë³¸ í–„ë¦¿ì—ì„œ ì‹¤ì œ ë¬¸ì¥ ì˜ˆì‹œ:\")\n",
        "if len(hamlet_text) > 1000:\n",
        "    # ì›ë³¸ì—ì„œ ëª‡ ê°œ ë¬¸ì¥ ì¶”ì¶œ\n",
        "    sentences = hamlet_text.split('.')[:3]\n",
        "    for i, sentence in enumerate(sentences, 1):\n",
        "        clean_sentence = ' '.join(sentence.split())[:80]\n",
        "        if clean_sentence:\n",
        "            print(f\"  {i}. {clean_sentence}...\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ê²°ë¡ \n",
        "\n",
        "ì´ ë…¸íŠ¸ë¶ì—ì„œ ìš°ë¦¬ëŠ”:\n",
        "\n",
        "1. **ë§ˆë¥´ì½”í”„ ì²´ì¸ì˜ ê¸°ë³¸ ê°œë…**ì„ ì´í•´í–ˆìŠµë‹ˆë‹¤\n",
        "2. **í…ìŠ¤íŠ¸ ì „ì²˜ë¦¬ì™€ ë‹¨ì–´ ìŒ ìƒì„±** ê³¼ì •ì„ í•™ìŠµí–ˆìŠµë‹ˆë‹¤  \n",
        "3. **í™•ë¥ ì  í…ìŠ¤íŠ¸ ìƒì„±** ë°©ë²•ì„ êµ¬í˜„í–ˆìŠµë‹ˆë‹¤\n",
        "4. **ì‹¤ì œ ë¬¸í•™ ì‘í’ˆì„ í™œìš©í•œ í…ìŠ¤íŠ¸ ìƒì„±**ì„ ìˆ˜í–‰í–ˆìŠµë‹ˆë‹¤\n",
        "5. **ë§ˆë¥´ì½”í”„ ì²´ì¸ì˜ íŠ¹ì„±ê³¼ í•œê³„**ë¥¼ ë¶„ì„í–ˆìŠµë‹ˆë‹¤\n",
        "\n",
        "ë§ˆë¥´ì½”í”„ ì²´ì¸ì€ ìì—°ì–´ ì²˜ë¦¬ì™€ í…ìŠ¤íŠ¸ ìƒì„±ì˜ ê¸°ì´ˆì ì´ë©´ì„œë„ ì¤‘ìš”í•œ ë°©ë²•ì…ë‹ˆë‹¤. ë¹„ë¡ í˜„ëŒ€ì˜ íŠ¸ëœìŠ¤í¬ë¨¸ ëª¨ë¸ë“¤ì— ë¹„í•´ ë‹¨ìˆœí•˜ì§€ë§Œ, í™•ë¥ ì  ì–¸ì–´ ëª¨ë¸ì˜ ê¸°ë³¸ ê°œë…ì„ ì´í•´í•˜ëŠ” ë° ë§¤ìš° ìœ ìš©í•©ë‹ˆë‹¤.\n",
        "\n",
        "### ì£¼ìš” í•™ìŠµ í¬ì¸íŠ¸:\n",
        "- **ë§ˆë¥´ì½”í”„ ê°€ì •**: í˜„ì¬ ìƒíƒœëŠ” ì§ì „ ìƒíƒœì—ë§Œ ì˜ì¡´\n",
        "- **ì „ì´ í™•ë¥ **: ë‹¨ì–´ ê°„ì˜ ì—°ê²° ë¹ˆë„ë¥¼ í†µí•œ í™•ë¥  ê³„ì‚°\n",
        "- **ëœë¤ ìƒì„±**: í™•ë¥  ë¶„í¬ì— ë”°ë¥¸ ë‹¤ìŒ ë‹¨ì–´ ì„ íƒ\n",
        "- **êµ­ë¶€ì  ì¼ê´€ì„±**: ì¸ì ‘í•œ ë‹¨ì–´ë“¤ ê°„ì˜ ìì—°ìŠ¤ëŸ¬ìš´ ì—°ê²°\n",
        "\n",
        "ë§ˆë¥´ì½”í”„ ì²´ì¸ì„ í†µí•´ ë°°ìš´ ì´ëŸ¬í•œ ê°œë…ë“¤ì€ ë” ë³µì¡í•œ ì–¸ì–´ ëª¨ë¸ì„ ì´í•´í•˜ëŠ” ê¸°ì´ˆê°€ ë©ë‹ˆë‹¤!\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.18"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
